"""
AIæ´å¯ŸåŠ©æ‰‹ä¸»å…¥å£è„šæœ¬
è´Ÿè´£åè°ƒæ•´ä¸ªè‡ªåŠ¨åŒ–æµæ°´çº¿çš„æ‰§è¡Œ
"""

import os
import sys
import logging
import argparse
from datetime import datetime
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from ai_processor import AIOrchestrator
from digest_generator import DigestTemplateRenderer

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/app.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)


def run_full_pipeline():
    """è¿è¡Œå®Œæ•´çš„AIå¤„ç†æµæ°´çº¿"""
    try:
        logger.info("ğŸš€ å¼€å§‹è¿è¡ŒAIæ´å¯ŸåŠ©æ‰‹å®Œæ•´æµæ°´çº¿")
        
        # 1. è¿è¡ŒAIå¤„ç†æµæ°´çº¿
        orchestrator = AIOrchestrator()
        pipeline_result = orchestrator.run_full_pipeline()
        
        if not pipeline_result['success']:
            logger.error(f"âŒ AIå¤„ç†æµæ°´çº¿å¤±è´¥: {pipeline_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            return False
        
        logger.info(f"âœ… AIå¤„ç†æµæ°´çº¿å®Œæˆ")
        logger.info(f"   è·å–å†…å®¹: {pipeline_result['total_fetched']}")
        logger.info(f"   å­˜å‚¨å†…å®¹: {pipeline_result['total_stored']}")
        logger.info(f"   å¤„ç†å†…å®¹: {pipeline_result['total_processed']}")
        logger.info(f"   è€—æ—¶: {pipeline_result['processing_time_seconds']:.2f} ç§’")
        
        # 2. ç”Ÿæˆæ—¥æŠ¥
        logger.info("ğŸ“° å¼€å§‹ç”ŸæˆAIæ—¥æŠ¥")
        renderer = DigestTemplateRenderer()
        digest_result = renderer.generate_daily_digest()
        
        if not digest_result['success']:
            logger.error(f"âŒ æ—¥æŠ¥ç”Ÿæˆå¤±è´¥: {digest_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            return False
        
        logger.info(f"âœ… æ—¥æŠ¥ç”ŸæˆæˆåŠŸ")
        logger.info(f"   æ—¥æŠ¥ID: {digest_result['digest_id']}")
        logger.info(f"   åŒ…å«æ´å¯Ÿ: {digest_result['stats']['total_insights']}")
        logger.info(f"   å†…å®¹é•¿åº¦: {len(digest_result['content'])} å­—ç¬¦")
        
        # 3. æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = orchestrator.get_processing_stats()
        logger.info("ğŸ“Š ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯:")
        logger.info(f"   åŸå§‹å†…å®¹æ€»æ•°: {stats.get('total_raw_content', 0)}")
        logger.info(f"   å·²å¤„ç†å†…å®¹: {stats.get('processed_content', 0)}")
        logger.info(f"   æœªå¤„ç†å†…å®¹: {stats.get('unprocessed_content', 0)}")
        logger.info(f"   æ´å¯Ÿæ€»æ•°: {stats.get('total_insights', 0)}")
        logger.info(f"   å¤„ç†ç‡: {stats.get('processing_rate', 0):.1f}%")
        
        logger.info("ğŸ‰ å®Œæ•´æµæ°´çº¿æ‰§è¡ŒæˆåŠŸï¼")
        logger.info("ğŸ“§ è¯·æ£€æŸ¥æ‚¨çš„é‚®ç®±ï¼Œæˆ–è®¿é—®å®¡æ ¸ç•Œé¢è¿›è¡Œæœ€ç»ˆå®¡æ ¸å’Œå‘å¸ƒ")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ æµæ°´çº¿æ‰§è¡Œå¤±è´¥: {e}")
        return False


def run_data_fetching_only():
    """ä»…è¿è¡Œæ•°æ®è·å–é˜¶æ®µ"""
    try:
        logger.info("ğŸ“¥ å¼€å§‹è¿è¡Œæ•°æ®è·å–é˜¶æ®µ")
        
        orchestrator = AIOrchestrator()
        
        # åªè¿è¡Œæ•°æ®è·å–å’Œå­˜å‚¨
        raw_contents = orchestrator._fetch_all_content()
        stored_count = orchestrator._store_raw_content(raw_contents)
        
        logger.info(f"âœ… æ•°æ®è·å–å®Œæˆ")
        logger.info(f"   è·å–å†…å®¹: {len(raw_contents)}")
        logger.info(f"   å­˜å‚¨å†…å®¹: {stored_count}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®è·å–å¤±è´¥: {e}")
        return False


def run_ai_processing_only():
    """ä»…è¿è¡ŒAIå¤„ç†é˜¶æ®µ"""
    try:
        logger.info("ğŸ¤– å¼€å§‹è¿è¡ŒAIå¤„ç†é˜¶æ®µ")
        
        orchestrator = AIOrchestrator()
        processed_count = orchestrator._process_unprocessed_content()
        
        logger.info(f"âœ… AIå¤„ç†å®Œæˆ")
        logger.info(f"   å¤„ç†å†…å®¹: {processed_count}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ AIå¤„ç†å¤±è´¥: {e}")
        return False


def run_digest_generation_only():
    """ä»…è¿è¡Œæ—¥æŠ¥ç”Ÿæˆé˜¶æ®µ"""
    try:
        logger.info("ğŸ“° å¼€å§‹è¿è¡Œæ—¥æŠ¥ç”Ÿæˆé˜¶æ®µ")
        
        renderer = DigestTemplateRenderer()
        result = renderer.generate_daily_digest()
        
        if not result['success']:
            logger.error(f"âŒ æ—¥æŠ¥ç”Ÿæˆå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            return False
        
        logger.info(f"âœ… æ—¥æŠ¥ç”ŸæˆæˆåŠŸ")
        logger.info(f"   æ—¥æŠ¥ID: {result['digest_id']}")
        logger.info(f"   åŒ…å«æ´å¯Ÿ: {result['stats']['total_insights']}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ—¥æŠ¥ç”Ÿæˆå¤±è´¥: {e}")
        return False


def show_status():
    """æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€"""
    try:
        logger.info("ğŸ“Š æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€")
        
        orchestrator = AIOrchestrator()
        stats = orchestrator.get_processing_stats()
        
        print("\n" + "="*50)
        print("ğŸ¤– AIæ´å¯ŸåŠ©æ‰‹ç³»ç»ŸçŠ¶æ€")
        print("="*50)
        print(f"ğŸ“… æ£€æŸ¥æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ“Š åŸå§‹å†…å®¹æ€»æ•°: {stats.get('total_raw_content', 0)}")
        print(f"âœ… å·²å¤„ç†å†…å®¹: {stats.get('processed_content', 0)}")
        print(f"â³ æœªå¤„ç†å†…å®¹: {stats.get('unprocessed_content', 0)}")
        print(f"ğŸ’¡ æ´å¯Ÿæ€»æ•°: {stats.get('total_insights', 0)}")
        print(f"ğŸ“ˆ å¤„ç†ç‡: {stats.get('processing_rate', 0):.1f}%")
        
        # æ£€æŸ¥æ—¥æŠ¥çŠ¶æ€
        renderer = DigestTemplateRenderer()
        latest_digest = renderer.get_latest_digest()
        
        if latest_digest:
            print(f"\nğŸ“° æœ€æ–°æ—¥æŠ¥:")
            print(f"   æ ‡é¢˜: {latest_digest['title']}")
            print(f"   çŠ¶æ€: {latest_digest['status']}")
            print(f"   åˆ›å»ºæ—¶é—´: {latest_digest['created_at']}")
            print(f"   å†…å®¹é•¿åº¦: {len(latest_digest['content'])} å­—ç¬¦")
        else:
            print("\nğŸ“° æš‚æ— æ—¥æŠ¥")
        
        print("="*50)
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ è·å–çŠ¶æ€å¤±è´¥: {e}")
        return False


def cleanup_old_data():
    """æ¸…ç†æ—§æ•°æ®"""
    try:
        logger.info("ğŸ§¹ å¼€å§‹æ¸…ç†æ—§æ•°æ®")
        
        orchestrator = AIOrchestrator()
        deleted_count = orchestrator.cleanup_old_content(days=30)
        
        logger.info(f"âœ… æ•°æ®æ¸…ç†å®Œæˆ")
        logger.info(f"   åˆ é™¤å†…å®¹: {deleted_count}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®æ¸…ç†å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='AIæ´å¯ŸåŠ©æ‰‹ - è‡ªåŠ¨åŒ–AIå†…å®¹åˆ†ææµæ°´çº¿')
    parser.add_argument('--mode', choices=['full', 'fetch', 'process', 'digest', 'status', 'cleanup'], 
                       default='full', help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--date', help='æŒ‡å®šæ—¥æœŸ (YYYY-MM-DD)')
    
    args = parser.parse_args()
    
    # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
    os.makedirs('logs', exist_ok=True)
    
    logger.info("ğŸ¤– AIæ´å¯ŸåŠ©æ‰‹å¯åŠ¨")
    logger.info(f"è¿è¡Œæ¨¡å¼: {args.mode}")
    if args.date:
        logger.info(f"æŒ‡å®šæ—¥æœŸ: {args.date}")
    
    try:
        if args.mode == 'full':
            success = run_full_pipeline()
        elif args.mode == 'fetch':
            success = run_data_fetching_only()
        elif args.mode == 'process':
            success = run_ai_processing_only()
        elif args.mode == 'digest':
            success = run_digest_generation_only()
        elif args.mode == 'status':
            success = show_status()
        elif args.mode == 'cleanup':
            success = cleanup_old_data()
        else:
            logger.error(f"æœªçŸ¥çš„è¿è¡Œæ¨¡å¼: {args.mode}")
            return 1
        
        if success:
            logger.info("âœ… æ“ä½œæ‰§è¡ŒæˆåŠŸ")
            return 0
        else:
            logger.error("âŒ æ“ä½œæ‰§è¡Œå¤±è´¥")
            return 1
            
    except KeyboardInterrupt:
        logger.info("â¹ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        return 1
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå¼‚å¸¸: {e}")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
